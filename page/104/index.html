<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#ba4861"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#ba4861">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"finolo.gy","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.24.1","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.json","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Finology 大数据金融">
<meta property="og:url" content="https://finolo.gy/page/104/index.html">
<meta property="og:site_name" content="Finology 大数据金融">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Simon">
<meta property="article:tag" content="python, finance, python, quant, 量化">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://finolo.gy/page/104/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/104/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Finology 大数据金融</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.5.0/search.js" integrity="sha256-xFC6PJ82SL9b3WkGjFavNiA9gm5z6UBxWPiu4CYjptg=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  


  <script class="next-config" data-name="leancloud_visitors" type="application/json">{"enable":true,"app_id":"SfaSE3g5tgBX5HeHdlgjym1o-gzGzoHsz","app_key":"iTsJGCNiGxrdBjV47UDN6X8p","server_url":null,"security":false}</script>
  <script src="/js/third-party/statistics/lean-analytics.js" defer></script>


<link rel="dns-prefetch" href="https://my-waline-beryl.vercel.app/">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Finology 大数据金融</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">通过大数据以量化金融</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Simon</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">376</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">79</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">235</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://finolo.gy/2019/02/%E4%BD%BF%E7%94%A8Thriftserver%E5%92%8CBeeline/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Finology 大数据金融">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Finology 大数据金融">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/02/%E4%BD%BF%E7%94%A8Thriftserver%E5%92%8CBeeline/" class="post-title-link" itemprop="url">使用Thriftserver和Beeline</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-02-12 19:16:40" itemprop="dateCreated datePublished" datetime="2019-02-12T19:16:40+08:00">2019-02-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-23 10:01:15" itemprop="dateModified" datetime="2025-08-23T10:01:15+08:00">2025-08-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/Spark-SQL/" itemprop="url" rel="index"><span itemprop="name">Spark SQL</span></a>
        </span>
    </span>

  
    <span id="/2019/02/%E4%BD%BF%E7%94%A8Thriftserver%E5%92%8CBeeline/" class="post-meta-item leancloud_visitors" data-flag-title="使用Thriftserver和Beeline" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2019/02/%E4%BD%BF%E7%94%A8Thriftserver%E5%92%8CBeeline/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2019/02/%E4%BD%BF%E7%94%A8Thriftserver%E5%92%8CBeeline/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>我们已经有了<code>spark-shell</code>和<code>spark-sql</code>，为什么还要使用<code>Thriftserver</code>呢？</p>
<ol>
<li><p>每一个spark-shell &#x2F; spark-sql都是一个Spark Application。</p>
</li>
<li><p>Thriftserver不管启动多少个客户端（beeline &#x2F; code），都只会产生一个Spark Application</p>
</li>
</ol>
<h1 id="启动thriftserver"><a href="#启动thriftserver" class="headerlink" title="启动thriftserver"></a>启动thriftserver</h1><p>需要把MySQL JDBC驱动通过<code>jars</code>参数加入进来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/</span><br><span class="line"></span><br><span class="line">sbin/start-thriftserver.sh --master local[2] \</span><br><span class="line">--jars ~/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar</span><br></pre></td></tr></table></figure>

<h2 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jps -m</span><br><span class="line"></span><br><span class="line">21522 SparkSubmit --master local[2] --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2</span><br><span class="line">--name Thrift JDBC/ODBC Server </span><br><span class="line">--jars /Users/simon/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar spark-internal</span><br><span class="line">3459 Worker --webui-port 8081 spark://localhost:7077</span><br><span class="line">18420 SparkSubmit --master local[2] --class org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver </span><br><span class="line">--jars /Users/simon/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar spark-internal</span><br></pre></td></tr></table></figure>

<p>我们看到有两个SparkSubmit进程，21522那个进程就是刚才启动的那个，class是<code>HiveThriftServer2</code>。</p>
<p>以spark-shell方式启动的class是<code>SparkSQLCLIDriver</code>。</p>
<h2 id="thriftserver端口"><a href="#thriftserver端口" class="headerlink" title="thriftserver端口"></a>thriftserver端口</h2><p>默认端口为<code>10000</code>，可以修改为其他端口。</p>
<p>在启动时增加<code>hiveconf</code>参数，比如把端口号设置为<code>14000</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--hiveconf hive.server2.thrift.port = 14000</span><br></pre></td></tr></table></figure>

<h1 id="beeline访问thriftserver"><a href="#beeline访问thriftserver" class="headerlink" title="beeline访问thriftserver"></a>beeline访问thriftserver</h1><p>需要设置jdbc uri: jdbc:hive2:&#x2F;&#x2F;localhost:10000</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">bin/beeline -u jdbc:hive2://localhost:10000 -n simon</span><br><span class="line">Connecting to jdbc:hive2://localhost:10000</span><br><span class="line">log4j:WARN No appenders could be found for logger (org.apache.hive.jdbc.Utils).</span><br><span class="line">log4j:WARN Please initialize the log4j system properly.</span><br><span class="line">log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.</span><br><span class="line">Connected to: Spark SQL (version 2.2.3)</span><br><span class="line">Driver: Hive JDBC (version 1.2.1.spark2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 1.2.1.spark2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://localhost:10000&gt;</span><br></pre></td></tr></table></figure>

<p>查看<code>emp</code>表的内容。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://localhost:10000&gt; SELECT * FROM emp;</span><br><span class="line">+--------+---------+------------+-------+-----------+---------+---------+---------+--+</span><br><span class="line">| empno  |  ename  |    job     |  mgr  | hiredate  |   sal   |  comm   | deptno  |</span><br><span class="line">+--------+---------+------------+-------+-----------+---------+---------+---------+--+</span><br><span class="line">| 7369   | SMITH   | CLERK      | 7902  | NULL      | 800.0   | NULL    | 20      |</span><br><span class="line">| 7499   | ALLEN   | SALESMAN   | 7698  | NULL      | 1600.0  | 300.0   | 30      |</span><br><span class="line">| 7521   | WARD    | SALESMAN   | 7698  | NULL      | 1250.0  | 500.0   | 30      |</span><br><span class="line">| 7566   | JONES   | MANAGER    | 7839  | NULL      | 2975.0  | NULL    | 20      |</span><br><span class="line">| 7654   | MARTIN  | SALESMAN   | 7698  | NULL      | 1250.0  | 1400.0  | 30      |</span><br><span class="line">| 7698   | BLAKE   | MANAGER    | 7839  | NULL      | 2850.0  | NULL    | 30      |</span><br><span class="line">| 7782   | CLARK   | MANAGER    | 7839  | NULL      | 2450.0  | NULL    | 10      |</span><br><span class="line">| 7788   | SCOTT   | ANALYST    | 7566  | NULL      | 3000.0  | NULL    | 20      |</span><br><span class="line">| 7839   | KING    | PRESIDENT  | NULL  | NULL      | 5000.0  | NULL    | 10      |</span><br><span class="line">| 7844   | TURNER  | SALESMAN   | 7698  | NULL      | 1500.0  | 0.0     | 30      |</span><br><span class="line">| 7876   | ADAMS   | CLERK      | 7788  | NULL      | 1100.0  | NULL    | 20      |</span><br><span class="line">| 7900   | JAMES   | CLERK      | 7698  | NULL      | 950.0   | NULL    | 30      |</span><br><span class="line">| 7902   | FORD    | ANALYST    | 7566  | NULL      | 3000.0  | NULL    | 20      |</span><br><span class="line">| 7934   | MILLER  | CLERK      | 7782  | NULL      | 1300.0  | NULL    | 10      |</span><br><span class="line">+--------+---------+------------+-------+-----------+---------+---------+---------+--+</span><br><span class="line">14 rows selected (0.411 seconds)</span><br></pre></td></tr></table></figure>

<h1 id="通过程序访问thriftserver"><a href="#通过程序访问thriftserver" class="headerlink" title="通过程序访问thriftserver"></a>通过程序访问thriftserver</h1><h2 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Thriftserver 支持 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hive<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hive-jdbc<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="SparkSQLThriftServerApp"><a href="#SparkSQLThriftServerApp" class="headerlink" title="SparkSQLThriftServerApp"></a>SparkSQLThriftServerApp</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> gy.finolo.spark</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.sql.<span class="type">DriverManager</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSQLThriftServerApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 加载驱动</span></span><br><span class="line">    <span class="type">Class</span>.forName(<span class="string">&quot;org.apache.hive.jdbc.HiveDriver&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 获取连接</span></span><br><span class="line">    <span class="keyword">val</span> conn = <span class="type">DriverManager</span>.getConnection(<span class="string">&quot;jdbc:hive2://localhost:10000&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> ps = conn.prepareStatement(<span class="string">&quot;SELECT empno, ename, sal FROM emp&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> rs = ps.executeQuery()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">      println(<span class="string">&quot;empno: &quot;</span> + rs.getInt(<span class="string">&quot;empno&quot;</span>) +</span><br><span class="line">        <span class="string">&quot;, ename: &quot;</span> + rs.getString(<span class="string">&quot;ename&quot;</span>) +</span><br><span class="line">        <span class="string">&quot;, salary: &quot;</span> + rs.getDouble(<span class="string">&quot;sal&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    rs.close()</span><br><span class="line">    ps.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">empno: 7369, ename: SMITH, salary: 800.0</span><br><span class="line">empno: 7499, ename: ALLEN, salary: 1600.0</span><br><span class="line">empno: 7521, ename: WARD, salary: 1250.0</span><br><span class="line">empno: 7566, ename: JONES, salary: 2975.0</span><br><span class="line">empno: 7654, ename: MARTIN, salary: 1250.0</span><br><span class="line">empno: 7698, ename: BLAKE, salary: 2850.0</span><br><span class="line">empno: 7782, ename: CLARK, salary: 2450.0</span><br><span class="line">empno: 7788, ename: SCOTT, salary: 3000.0</span><br><span class="line">empno: 7839, ename: KING, salary: 5000.0</span><br><span class="line">empno: 7844, ename: TURNER, salary: 1500.0</span><br><span class="line">empno: 7876, ename: ADAMS, salary: 1100.0</span><br><span class="line">empno: 7900, ename: JAMES, salary: 950.0</span><br><span class="line">empno: 7902, ename: FORD, salary: 3000.0</span><br><span class="line">empno: 7934, ename: MILLER, salary: 1300.0</span><br></pre></td></tr></table></figure>

<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><ol>
<li>通过程序访问thriftserver前，得保证thriftserver已经启动，不然运行程序时，会遇到如下错误：</li>
</ol>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.sql.SQLException: Could not open client transport with JDBC Uri: </span><br><span class="line">jdbc:hive2://localhost:10000: java.net.ConnectException: Connection refused (Connection refused)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>我安装的Hive版本是<code>hive-1.1.0-cdh5.7.0</code>，但我在pom.xml里依赖的jar版本不对时，可能遇到如下异常。</li>
</ol>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.sql.SQLException: Could not open client transport with JDBC Uri: </span><br><span class="line">jdbc:hive2://localhost:10000: Could not establish connection to jdbc:hive2://localhost:10000: </span><br><span class="line">Required field &#x27;client_protocol&#x27; is unset! Struct:TOpenSessionReq(client_protocol:null, </span><br><span class="line">configuration:&#123;use:database=default&#125;)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://finolo.gy/2019/02/%E4%BB%8EHive%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%E5%88%B0Spark-SQL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Finology 大数据金融">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Finology 大数据金融">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/02/%E4%BB%8EHive%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%E5%88%B0Spark-SQL/" class="post-title-link" itemprop="url">从Hive平滑过渡到Spark SQL</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-02-12 15:19:15" itemprop="dateCreated datePublished" datetime="2019-02-12T15:19:15+08:00">2019-02-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-23 10:01:15" itemprop="dateModified" datetime="2025-08-23T10:01:15+08:00">2025-08-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/Spark-SQL/" itemprop="url" rel="index"><span itemprop="name">Spark SQL</span></a>
        </span>
    </span>

  
    <span id="/2019/02/%E4%BB%8EHive%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%E5%88%B0Spark-SQL/" class="post-meta-item leancloud_visitors" data-flag-title="从Hive平滑过渡到Spark SQL" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2019/02/%E4%BB%8EHive%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%E5%88%B0Spark-SQL/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2019/02/%E4%BB%8EHive%E5%B9%B3%E6%BB%91%E8%BF%87%E6%B8%A1%E5%88%B0Spark-SQL/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>这篇文章记录一下如何在Spark下面像Hive一样查询表的内容。</p>
<h1 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master local[2]</span><br></pre></td></tr></table></figure>

<h1 id="查看一下有哪些表"><a href="#查看一下有哪些表" class="headerlink" title="查看一下有哪些表"></a>查看一下有哪些表</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(&quot;show tables&quot;).show</span><br><span class="line">19/02/12 14:37:49 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0</span><br><span class="line">19/02/12 14:37:49 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException</span><br><span class="line">19/02/12 14:37:50 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">|database|tableName|isTemporary|</span><br><span class="line">+--------+---------+-----------+</span><br><span class="line">+--------+---------+-----------+</span><br></pre></td></tr></table></figure>

<p>没有查看到东西。</p>
<p>所以需要把hive下面的<code>hive-site.xml</code>文件复制到spark下面。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp $HIVE_HOME/conf/hive-site.xml $SPARK_HOME/conf</span><br></pre></td></tr></table></figure>

<h1 id="重启Spark"><a href="#重启Spark" class="headerlink" title="重启Spark"></a>重启Spark</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master local[2]</span><br></pre></td></tr></table></figure>

<p>再次执行命令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(&quot;show tables&quot;).show</span><br><span class="line"></span><br><span class="line">19/02/12 15:53:46 WARN HiveMetaStore: Retrying creating default database after error: Error creating transactional connection factory</span><br><span class="line">javax.jdo.JDOFatalInternalException: Error creating transactional connection factory</span><br><span class="line"></span><br><span class="line">Caused by: org.datanucleus.store.rdbms.connectionpool.DatastoreDriverNotFoundException: </span><br><span class="line">The specified datastore driver (&quot;com.mysql.jdbc.Driver&quot;) was not found in the CLASSPATH. </span><br><span class="line">Please check your CLASSPATH specification, and the name of the driver.</span><br></pre></td></tr></table></figure>

<p>说明MySQL的驱动未被加载。</p>
<p>第三次启动Spark，通过参数<code>--jars</code>指定MySQL驱动的位置。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell --master local[2] \</span><br><span class="line">--jars ~/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar</span><br></pre></td></tr></table></figure>

<h1 id="查看表"><a href="#查看表" class="headerlink" title="查看表"></a>查看表</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(&quot;show tables&quot;).show</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">+--------+--------------+-----------+</span><br><span class="line">|database|     tableName|isTemporary|</span><br><span class="line">+--------+--------------+-----------+</span><br><span class="line">| default|           emp|      false|</span><br><span class="line">| default|hive_wordcount|      false|</span><br><span class="line">+--------+--------------+-----------+</span><br></pre></td></tr></table></figure>

<p>可以看到有两个表，<code>emp</code>和<code>hive_wordcount</code>。</p>
<h1 id="验证SQL查询"><a href="#验证SQL查询" class="headerlink" title="验证SQL查询"></a>验证SQL查询</h1><h2 id="在hive-client里面新建一个dept表"><a href="#在hive-client里面新建一个dept表" class="headerlink" title="在hive client里面新建一个dept表"></a>在hive client里面新建一个dept表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;</span><br><span class="line">CREATE TABLE dept(</span><br><span class="line">	deptno		INT,</span><br><span class="line">	dname		STRING,</span><br><span class="line">	loc			STRING)</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<h2 id="创建dept数据文件"><a href="#创建dept数据文件" class="headerlink" title="创建dept数据文件"></a>创建dept数据文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/local/spark/data/dept</span><br><span class="line"></span><br><span class="line">10  ACCOUNTING  NEW YORK</span><br><span class="line">20  RESEARCH    DALLAS</span><br><span class="line">30  SALES   CHICAGO</span><br><span class="line">40  OPERATIONS	BOSTON</span><br></pre></td></tr></table></figure>

<p>中间字段间间隔的是tab。</p>
<h2 id="加载数据到dept表里"><a href="#加载数据到dept表里" class="headerlink" title="加载数据到dept表里"></a>加载数据到dept表里</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA LOCAL INPATH &#x27;/usr/local/spark/data/dept&#x27; OVERWRITE INTO TABLE dept;</span><br></pre></td></tr></table></figure>

<p><code>OVERWRITE</code>参数的意义是：如果表里面有旧的数据，可以通过<code>OVERWRITE</code>先清除旧数据。</p>
<h2 id="验证查询"><a href="#验证查询" class="headerlink" title="验证查询"></a>验证查询</h2><p>回到spark shell。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; spark.sql(&quot;SELECT * FROM dept&quot;).show</span><br><span class="line">+------+----------+--------+</span><br><span class="line">|deptno|     dname|     loc|</span><br><span class="line">+------+----------+--------+</span><br><span class="line">|    10|ACCOUNTING|NEW YORK|</span><br><span class="line">|    20|  RESEARCH|  DALLAS|</span><br><span class="line">|    30|     SALES| CHICAGO|</span><br><span class="line">|    40|OPERATIONS|  BOSTON|</span><br><span class="line">+------+----------+--------+</span><br></pre></td></tr></table></figure>

<h1 id="如果省略spark-sql"><a href="#如果省略spark-sql" class="headerlink" title="如果省略spark.sql"></a>如果省略spark.sql</h1><p>我们发现在执行SQL语句时，我们在都需要写<code>spark.sql(sql query).show</code>。这样比起hive来，就没那么简便。</p>
<p>其实是可以通过启动spark-sql来达到这个简化目标的。</p>
<p>能spark-sql方式启动spark shell。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-sql --master local[2] \</span><br><span class="line">--jars ~/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar</span><br></pre></td></tr></table></figure>

<p>启动后，直接写SQL语句查询</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-sql&gt; SELECT * FROM emp e JOIN dept d ON e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<p>将返回如下内容：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">19/02/12 16:39:50 INFO DAGScheduler: Job 1 finished: processCmd at CliDriver.java:376, took 0.059725 s</span><br><span class="line">7369	SMITH	CLERK	7902	NULL	800.0	NULL	20	20	RESEARCH	DALLAS</span><br><span class="line">7499	ALLEN	SALESMAN	7698	NULL	1600.0	300.0	30	30	SALES	CHICAGO</span><br><span class="line">7521	WARD	SALESMAN	7698	NULL	1250.0	500.0	30	30	SALES	CHICAGO</span><br><span class="line">7566	JONES	MANAGER	7839	NULL	2975.0	NULL	20	20	RESEARCH	DALLAS</span><br><span class="line">7654	MARTIN	SALESMAN	7698	NULL	1250.0	1400.0	30	30	SALES	CHICAGO</span><br><span class="line">7698	BLAKE	MANAGER	7839	NULL	2850.0	NULL	30	30	SALES	CHICAGO</span><br><span class="line">7782	CLARK	MANAGER	7839	NULL	2450.0	NULL	10	10	ACCOUNTING	NEW YORK</span><br><span class="line">7788	SCOTT	ANALYST	7566	NULL	3000.0	NULL	20	20	RESEARCH	DALLAS</span><br><span class="line">7839	KING	PRESIDENT	NULL	NULL	5000.0	NULL	10	10	ACCOUNTING	NEW YORK</span><br><span class="line">7844	TURNER	SALESMAN	7698	NULL	1500.0	0.0	30	30	SALES	CHICAGO</span><br><span class="line">7876	ADAMS	CLERK	7788	NULL	1100.0	NULL	20	20	RESEARCH	DALLAS</span><br><span class="line">7900	JAMES	CLERK	7698	NULL	950.0	NULL	30	30	SALES	CHICAGO</span><br><span class="line">7902	FORD	ANALYST	7566	NULL	3000.0	NULL	20	20	RESEARCH	DALLAS</span><br><span class="line">7934	MILLER	CLERK	7782	NULL	1300.0	NULL	10	10	ACCOUNTING	NEW YORK</span><br><span class="line">Time taken: 3.793 seconds, Fetched 14 row(s)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h1 id="查看执行计划"><a href="#查看执行计划" class="headerlink" title="查看执行计划"></a>查看执行计划</h1><h2 id="创建一个表"><a href="#创建一个表" class="headerlink" title="创建一个表"></a>创建一个表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> <span class="keyword">CREATE TABLE</span> t (key STRING, <span class="keyword">value</span> STRING);</span><br></pre></td></tr></table></figure>

<h2 id="执行如下SQL语句"><a href="#执行如下SQL语句" class="headerlink" title="执行如下SQL语句"></a>执行如下SQL语句</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">spark<span class="operator">-</span><span class="keyword">sql</span><span class="operator">&gt;</span> EXPLAIN EXTENDED <span class="keyword">SELECT</span> a.key <span class="operator">*</span> (<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">FROM</span> t a <span class="keyword">JOIN</span> t b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key <span class="keyword">AND</span> a.key <span class="operator">&gt;</span> <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO SparkSqlParser: Parsing command: EXPLAIN EXTENDED <span class="keyword">SELECT</span> a.key <span class="operator">*</span> (<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">FROM</span> t a <span class="keyword">JOIN</span> t b <span class="keyword">ON</span> a.key <span class="operator">=</span> b.key <span class="keyword">AND</span> a.key <span class="operator">&gt;</span> <span class="number">3</span></span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO HiveMetaStore: <span class="number">0</span>: get_table : db<span class="operator">=</span><span class="keyword">default</span> tbl<span class="operator">=</span>t</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO audit: ugi<span class="operator">=</span>simon	ip<span class="operator">=</span><span class="literal">unknown</span><span class="operator">-</span>ip<span class="operator">-</span>addr	cmd<span class="operator">=</span>get_table : db<span class="operator">=</span><span class="keyword">default</span> tbl<span class="operator">=</span>t</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO CatalystSqlParser: Parsing command: string</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO CatalystSqlParser: Parsing command: string</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO HiveMetaStore: <span class="number">0</span>: get_table : db<span class="operator">=</span><span class="keyword">default</span> tbl<span class="operator">=</span>t</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO audit: ugi<span class="operator">=</span>simon	ip<span class="operator">=</span><span class="literal">unknown</span><span class="operator">-</span>ip<span class="operator">-</span>addr	cmd<span class="operator">=</span>get_table : db<span class="operator">=</span><span class="keyword">default</span> tbl<span class="operator">=</span>t</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO CatalystSqlParser: Parsing command: string</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO CatalystSqlParser: Parsing command: string</span><br><span class="line"><span class="operator">=</span><span class="operator">=</span> Parsed Logical Plan <span class="operator">=</span><span class="operator">=</span></span><br><span class="line"><span class="string">&#x27;Project [unresolvedalias((&#x27;</span>a.key <span class="operator">*</span> (<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>)), <span class="keyword">None</span>)]</span><br><span class="line"><span class="operator">+</span><span class="operator">-</span> <span class="string">&#x27;Join Inner, ((&#x27;</span>a.key <span class="operator">=</span> <span class="string">&#x27;b.key) &amp;&amp; (&#x27;</span>a.key <span class="operator">&gt;</span> <span class="number">3</span>))</span><br><span class="line">   :<span class="operator">-</span> <span class="string">&#x27;SubqueryAlias a</span></span><br><span class="line"><span class="string">   :  +- &#x27;</span>UnresolvedRelation `t`</span><br><span class="line">   <span class="operator">+</span><span class="operator">-</span> <span class="string">&#x27;SubqueryAlias b</span></span><br><span class="line"><span class="string">      +- &#x27;</span>UnresolvedRelation `t`</span><br><span class="line"></span><br><span class="line"><span class="operator">=</span><span class="operator">=</span> Analyzed Logical Plan <span class="operator">=</span><span class="operator">=</span></span><br><span class="line">(<span class="built_in">CAST</span>(key <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>) <span class="operator">*</span> <span class="built_in">CAST</span>((<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>)): <span class="keyword">double</span></span><br><span class="line">Project [(<span class="built_in">cast</span>(key#<span class="number">34</span> <span class="keyword">as</span> <span class="keyword">double</span>) <span class="operator">*</span> <span class="built_in">cast</span>((<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">as</span> <span class="keyword">double</span>)) <span class="keyword">AS</span> (<span class="built_in">CAST</span>(key <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>) <span class="operator">*</span> <span class="built_in">CAST</span>((<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>))#<span class="number">38</span>]</span><br><span class="line"><span class="operator">+</span><span class="operator">-</span> <span class="keyword">Join</span> <span class="keyword">Inner</span>, ((key#<span class="number">34</span> <span class="operator">=</span> key#<span class="number">36</span>) <span class="operator">&amp;&amp;</span> (<span class="built_in">cast</span>(key#<span class="number">34</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">&gt;</span> <span class="number">3</span>))</span><br><span class="line">   :<span class="operator">-</span> SubqueryAlias a</span><br><span class="line">   :  <span class="operator">+</span><span class="operator">-</span> SubqueryAlias t</span><br><span class="line">   :     <span class="operator">+</span><span class="operator">-</span> HiveTableRelation `<span class="keyword">default</span>`.`t`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, [key#<span class="number">34</span>, <span class="keyword">value</span>#<span class="number">35</span>]</span><br><span class="line">   <span class="operator">+</span><span class="operator">-</span> SubqueryAlias b</span><br><span class="line">      <span class="operator">+</span><span class="operator">-</span> SubqueryAlias t</span><br><span class="line">         <span class="operator">+</span><span class="operator">-</span> HiveTableRelation `<span class="keyword">default</span>`.`t`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, [key#<span class="number">36</span>, <span class="keyword">value</span>#<span class="number">37</span>]</span><br><span class="line"></span><br><span class="line"><span class="operator">=</span><span class="operator">=</span> Optimized Logical Plan <span class="operator">=</span><span class="operator">=</span></span><br><span class="line">Project [(<span class="built_in">cast</span>(key#<span class="number">34</span> <span class="keyword">as</span> <span class="keyword">double</span>) <span class="operator">*</span> <span class="number">5.0</span>) <span class="keyword">AS</span> (<span class="built_in">CAST</span>(key <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>) <span class="operator">*</span> <span class="built_in">CAST</span>((<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>))#<span class="number">38</span>]</span><br><span class="line"><span class="operator">+</span><span class="operator">-</span> <span class="keyword">Join</span> <span class="keyword">Inner</span>, (key#<span class="number">34</span> <span class="operator">=</span> key#<span class="number">36</span>)</span><br><span class="line">   :<span class="operator">-</span> Project [key#<span class="number">34</span>]</span><br><span class="line">   :  <span class="operator">+</span><span class="operator">-</span> <span class="keyword">Filter</span> (isnotnull(key#<span class="number">34</span>) <span class="operator">&amp;&amp;</span> (<span class="built_in">cast</span>(key#<span class="number">34</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">&gt;</span> <span class="number">3</span>))</span><br><span class="line">   :     <span class="operator">+</span><span class="operator">-</span> HiveTableRelation `<span class="keyword">default</span>`.`t`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, [key#<span class="number">34</span>, <span class="keyword">value</span>#<span class="number">35</span>]</span><br><span class="line">   <span class="operator">+</span><span class="operator">-</span> Project [key#<span class="number">36</span>]</span><br><span class="line">      <span class="operator">+</span><span class="operator">-</span> <span class="keyword">Filter</span> (isnotnull(key#<span class="number">36</span>) <span class="operator">&amp;&amp;</span> (<span class="built_in">cast</span>(key#<span class="number">36</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">&gt;</span> <span class="number">3</span>))</span><br><span class="line">         <span class="operator">+</span><span class="operator">-</span> HiveTableRelation `<span class="keyword">default</span>`.`t`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, [key#<span class="number">36</span>, <span class="keyword">value</span>#<span class="number">37</span>]</span><br><span class="line"></span><br><span class="line"><span class="operator">=</span><span class="operator">=</span> Physical Plan <span class="operator">=</span><span class="operator">=</span></span><br><span class="line"><span class="operator">*</span>Project [(<span class="built_in">cast</span>(key#<span class="number">34</span> <span class="keyword">as</span> <span class="keyword">double</span>) <span class="operator">*</span> <span class="number">5.0</span>) <span class="keyword">AS</span> (<span class="built_in">CAST</span>(key <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>) <span class="operator">*</span> <span class="built_in">CAST</span>((<span class="number">2</span> <span class="operator">+</span> <span class="number">3</span>) <span class="keyword">AS</span> <span class="keyword">DOUBLE</span>))#<span class="number">38</span>]</span><br><span class="line"><span class="operator">+</span><span class="operator">-</span> <span class="operator">*</span>SortMergeJoin [key#<span class="number">34</span>], [key#<span class="number">36</span>], <span class="keyword">Inner</span></span><br><span class="line">   :<span class="operator">-</span> <span class="operator">*</span>Sort [key#<span class="number">34</span> <span class="keyword">ASC</span> <span class="keyword">NULLS FIRST</span>], <span class="literal">false</span>, <span class="number">0</span></span><br><span class="line">   :  <span class="operator">+</span><span class="operator">-</span> Exchange hashpartitioning(key#<span class="number">34</span>, <span class="number">200</span>)</span><br><span class="line">   :     <span class="operator">+</span><span class="operator">-</span> <span class="operator">*</span><span class="keyword">Filter</span> (isnotnull(key#<span class="number">34</span>) <span class="operator">&amp;&amp;</span> (<span class="built_in">cast</span>(key#<span class="number">34</span> <span class="keyword">as</span> <span class="type">int</span>) <span class="operator">&gt;</span> <span class="number">3</span>))</span><br><span class="line">   :        <span class="operator">+</span><span class="operator">-</span> HiveTableScan [key#<span class="number">34</span>], HiveTableRelation `<span class="keyword">default</span>`.`t`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, [key#<span class="number">34</span>, <span class="keyword">value</span>#<span class="number">35</span>]</span><br><span class="line">   <span class="operator">+</span><span class="operator">-</span> <span class="operator">*</span>Sort [key#<span class="number">36</span> <span class="keyword">ASC</span> <span class="keyword">NULLS FIRST</span>], <span class="literal">false</span>, <span class="number">0</span></span><br><span class="line">      <span class="operator">+</span><span class="operator">-</span> ReusedExchange [key#<span class="number">36</span>], Exchange hashpartitioning(key#<span class="number">34</span>, <span class="number">200</span>)</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.117</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line"><span class="number">19</span><span class="operator">/</span><span class="number">02</span><span class="operator">/</span><span class="number">12</span> <span class="number">16</span>:<span class="number">45</span>:<span class="number">52</span> INFO CliDriver: <span class="type">Time</span> taken: <span class="number">0.117</span> seconds, Fetched <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>关于执行计划的详细分析，我们会在后面的博客中详细分享。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://finolo.gy/2019/02/%E5%88%9B%E5%BB%BASpark-SQL-Hive%E7%A8%8B%E5%BA%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Finology 大数据金融">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content=" | Finology 大数据金融">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/02/%E5%88%9B%E5%BB%BASpark-SQL-Hive%E7%A8%8B%E5%BA%8F/" class="post-title-link" itemprop="url">创建Spark SQL Hive程序</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-02-11 22:49:47" itemprop="dateCreated datePublished" datetime="2019-02-11T22:49:47+08:00">2019-02-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-23 10:01:15" itemprop="dateModified" datetime="2025-08-23T10:01:15+08:00">2025-08-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/Spark-SQL/" itemprop="url" rel="index"><span itemprop="name">Spark SQL</span></a>
        </span>
    </span>

  
    <span id="/2019/02/%E5%88%9B%E5%BB%BASpark-SQL-Hive%E7%A8%8B%E5%BA%8F/" class="post-meta-item leancloud_visitors" data-flag-title="创建Spark SQL Hive程序" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="leancloud-visitors-count"></span>
    </span>
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2019/02/%E5%88%9B%E5%BB%BASpark-SQL-Hive%E7%A8%8B%E5%BA%8F/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2019/02/%E5%88%9B%E5%BB%BASpark-SQL-Hive%E7%A8%8B%E5%BA%8F/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在这篇文章中，我们将使用SparkSession，打印出Hive中的emp表的内容。</p>
<p>Spark SQL最基础程序，可以参考博文 <a href="/2019/02/%E5%88%9B%E5%BB%BASpark-SQL%E7%A8%8B%E5%BA%8F/" title="创建Spark SQL程序">创建Spark SQL程序</a></p>
<h1 id="创建SparkSessionHiveApp程序"><a href="#创建SparkSessionHiveApp程序" class="headerlink" title="创建SparkSessionHiveApp程序"></a>创建<code>SparkSessionHiveApp</code>程序</h1><h2 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scala.version</span>&gt;</span>2.11.12<span class="tag">&lt;/<span class="name">scala.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scala.compat.version</span>&gt;</span>2.11<span class="tag">&lt;/<span class="name">scala.compat.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">spark.version</span>&gt;</span>2.2.3<span class="tag">&lt;/<span class="name">spark.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.scala-lang<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>scala-library<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-sql_$&#123;scala.compat.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- hive support --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-hive_$&#123;scala.compat.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;spark.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.46<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="SparkSessionHiveApp"><a href="#SparkSessionHiveApp" class="headerlink" title="SparkSessionHiveApp"></a>SparkSessionHiveApp</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> gy.finolo.spark</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSessionHiveApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建Spark Session</span></span><br><span class="line">    <span class="keyword">val</span> sparkSession = <span class="type">SparkSession</span>.builder()</span><br><span class="line">      .master(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">      .appName(<span class="string">&quot;Spark Session Hive App&quot;</span>)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 业务处理</span></span><br><span class="line">    sparkSession.table(<span class="string">&quot;emp&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 关闭资源</span></span><br><span class="line">    sparkSession.stop()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="创建emp表"><a href="#创建emp表" class="headerlink" title="创建emp表"></a>创建emp表</h1><h2 id="创建emp原始文件"><a href="#创建emp原始文件" class="headerlink" title="创建emp原始文件"></a>创建emp原始文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /usr/local/spark/data/emp.csv</span><br></pre></td></tr></table></figure>

<p>写入如下内容到emp.csv文件中。注意，有些字段为空值。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369,SMITH,CLERK,7902,1980/12/17,800,,20</span><br><span class="line">7499,ALLEN,SALESMAN,7698,1981/2/20,1600,300,30</span><br><span class="line">7521,WARD,SALESMAN,7698,1981/2/22,1250,500,30</span><br><span class="line">7566,JONES,MANAGER,7839,1981/4/2,2975,,20</span><br><span class="line">7654,MARTIN,SALESMAN,7698,1981/9/28,1250,1400,30</span><br><span class="line">7698,BLAKE,MANAGER,7839,1981/5/1,2850,,30</span><br><span class="line">7782,CLARK,MANAGER,7839,1981/6/9,2450,,10</span><br><span class="line">7788,SCOTT,ANALYST,7566,1987/4/19,3000,,20</span><br><span class="line">7839,KING,PRESIDENT,,1981/11/17,5000,,10</span><br><span class="line">7844,TURNER,SALESMAN,7698,1981/9/8,1500,0,30</span><br><span class="line">7876,ADAMS,CLERK,7788,1987/5/23,1100,,20</span><br><span class="line">7900,JAMES,CLERK,7698,1981/12/3,950,,30</span><br><span class="line">7902,FORD,ANALYST,7566,1981/12/3,3000,,20</span><br><span class="line">7934,MILLER,CLERK,7782,1982/1/23,1300,,10</span><br></pre></td></tr></table></figure>

<h2 id="在Hive中创建emp表"><a href="#在Hive中创建emp表" class="headerlink" title="在Hive中创建emp表"></a>在Hive中创建emp表</h2><p>Hive的基本使用，可以参考博文 <a href="/2019/01/Hive%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="Hive环境搭建">Hive环境搭建</a></p>
<p>语句后面必须要有分号。</p>
<p>hive&gt;<br>CREATE TABLE emp(<br>empno   INT,<br>ename   STRING,<br>job     STRING,<br>mgr     INT,<br>hiredate DATE,<br>sal     DOUBLE,<br>comm    DOUBLE,<br>deptno  INT<br>) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘,’;</p>
<h2 id="导入数据到emp表中"><a href="#导入数据到emp表中" class="headerlink" title="导入数据到emp表中"></a>导入数据到emp表中</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA LOCAL INPATH &#x27;/usr/local/spark/data/emp.csv&#x27; INTO TABLE emp;</span><br></pre></td></tr></table></figure>

<p>hiredate这里有一些问题，以后再解决。</p>
<h2 id="在IDEA中运行程序"><a href="#在IDEA中运行程序" class="headerlink" title="在IDEA中运行程序"></a>在IDEA中运行程序</h2><p>可以看到emp表中的结果被成功打印在了控制台上。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">19/02/12 00:00:23 INFO DAGScheduler: Job 0 finished: show at SparkSessionHiveApp.scala:21, took 0.340480 s</span><br><span class="line">+-----+------+---------+----+--------+------+------+------+</span><br><span class="line">|empno| ename|      job| mgr|hiredate|   sal|  comm|deptno|</span><br><span class="line">+-----+------+---------+----+--------+------+------+------+</span><br><span class="line">| 7369| SMITH|    CLERK|7902|    null| 800.0|  null|    20|</span><br><span class="line">| 7499| ALLEN| SALESMAN|7698|    null|1600.0| 300.0|    30|</span><br><span class="line">| 7521|  WARD| SALESMAN|7698|    null|1250.0| 500.0|    30|</span><br><span class="line">| 7566| JONES|  MANAGER|7839|    null|2975.0|  null|    20|</span><br><span class="line">| 7654|MARTIN| SALESMAN|7698|    null|1250.0|1400.0|    30|</span><br><span class="line">| 7698| BLAKE|  MANAGER|7839|    null|2850.0|  null|    30|</span><br><span class="line">| 7782| CLARK|  MANAGER|7839|    null|2450.0|  null|    10|</span><br><span class="line">| 7788| SCOTT|  ANALYST|7566|    null|3000.0|  null|    20|</span><br><span class="line">| 7839|  KING|PRESIDENT|null|    null|5000.0|  null|    10|</span><br><span class="line">| 7844|TURNER| SALESMAN|7698|    null|1500.0|   0.0|    30|</span><br><span class="line">| 7876| ADAMS|    CLERK|7788|    null|1100.0|  null|    20|</span><br><span class="line">| 7900| JAMES|    CLERK|7698|    null| 950.0|  null|    30|</span><br><span class="line">| 7902|  FORD|  ANALYST|7566|    null|3000.0|  null|    20|</span><br><span class="line">| 7934|MILLER|    CLERK|7782|    null|1300.0|  null|    10|</span><br><span class="line">+-----+------+---------+----+--------+------+------+------+</span><br></pre></td></tr></table></figure>

<h1 id="打包并提交作业"><a href="#打包并提交作业" class="headerlink" title="打包并提交作业"></a>打包并提交作业</h1><p>在测试环境上面已经可以成功运行，我们现在打好包，以spark-submit方式提交作业。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--master local[2] \</span><br><span class="line">--class gy.finolo.spark.SparkSessionHiveApp \</span><br><span class="line">--jars /Users/simon/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar \</span><br><span class="line">/Users/simon/Development/workspace/scala/spark-sql-demo/target/spark-sql-demo-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<p>需要通过<code>jars</code>参数指定JDBC驱动的位置。</p>
<p>如果需要加载的jar很多怎么办？我将在以后的博文中讲到这个问题。</p>
<h1 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h1><h2 id="JDBC驱动未添加"><a href="#JDBC驱动未添加" class="headerlink" title="JDBC驱动未添加"></a>JDBC驱动未添加</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Caused by: org.datanucleus.store.rdbms.connectionpool.DatastoreDriverNotFoundException: </span><br><span class="line">The specified datastore driver (&quot;com.mysql.jdbc.Driver&quot;) was not found in the CLASSPATH. </span><br><span class="line">Please check your CLASSPATH specification, and the name of the driver.</span><br></pre></td></tr></table></figure>

<p>解决方案：</p>
<p>如果是在IDEA中开发运行的话，那需要添加驱动的jar包。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.46<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="DatastoreDriverNotFound"><a href="#DatastoreDriverNotFound" class="headerlink" title="DatastoreDriverNotFound"></a>DatastoreDriverNotFound</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.datanucleus.store.rdbms.connectionpool.DatastoreDriverNotFoundException: </span><br><span class="line">The specified datastore driver (&quot;com.mysql.jdbc.Driver&quot;) was not found in the CLASSPATH. </span><br><span class="line">Please check your CLASSPATH specification, and the name of the driver.</span><br></pre></td></tr></table></figure>

<p>和上面那个错误是类似的，我们在提交作业时，必须要通过<code>--jars</code>指定<code>mysql-connector-java.jar</code>的位置。</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--master local[2] \</span><br><span class="line">--class gy.finolo.spark.SparkSessionHiveApp \</span><br><span class="line">--jars /Users/simon/.m2/repository/mysql/mysql-connector-java/5.1.46/mysql-connector-java-5.1.46.jar \</span><br><span class="line">/Users/simon/Development/workspace/scala/spark-sql-demo/target/spark-sql-demo-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure>

<h2 id="Table-or-view-not-found"><a href="#Table-or-view-not-found" class="headerlink" title="Table or view not found"></a>Table or view not found</h2><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; org.apache.spark.sql.AnalysisException:</span><br><span class="line">Table or view not found: emp;</span><br></pre></td></tr></table></figure>

<p>解决方案：</p>
<p>把Hive conf下面的hive-site.xml拷贝到工程的resources目录下面。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/local/hive/hive-1.1.0-cdh5.7.0/conf/hive-site.xml spark-sql-demo/src/resources</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/103/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/103/">103</a><span class="page-number current">104</span><a class="page-number" href="/page/105/">105</a><span class="space">&hellip;</span><a class="page-number" href="/page/126/">126</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/105/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Simon</span>
  </div>
  <div class="powered-by">Powered by Finolo.gy
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-CN","enable":true,"serverURL":"https://my-waline-beryl.vercel.app/","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"appid":"SfaSE3g5tgBX5HeHdlgjym1o-gzGzoHsz","appkey":"iTsJGCNiGxrdBjV47UDN6X8p","placeholder":"来整几句？","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"visitor":true,"comment_count":true,"recordIP":false,"enableQQ":false,"requiredFields":[],"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","el":"#waline","comment":true,"path":"/page/104/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

</body>
</html>
